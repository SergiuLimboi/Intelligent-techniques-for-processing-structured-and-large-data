{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7892fa-7164-42db-9c76-1f6fddfa1d10",
   "metadata": {},
   "source": [
    "# Polars basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1fdc91-0309-49d3-be48-e41e4b39d81d",
   "metadata": {},
   "source": [
    "**Polars** is a high-performance DataFrame library for Python (and Rust) designed for fast analytics. Compared to pandas, Polars is typically faster and more memory-efficient because it uses:\n",
    "* operations work per column (great for analytics).\n",
    "* ou write what you want (filters, aggregates) and Polars optimizes it.\n",
    "* many operations run multi-threaded automatically.\n",
    "* uilds a query plan first, then executes efficiently (pushes filters/column selection down so it reads less data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800cc444-8f13-4f13-b5d0-09296fa53193",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa081a12-17aa-4df6-a179-f811b8ce2366",
   "metadata": {},
   "source": [
    "If you don't have them, install the following:\n",
    "* Python  (https://www.python.org/downloads/windows/)\n",
    "* Jupyter notebook/ Jupyter lab (https://jupyter.org/install) or Google Colab (https://colab.google/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e801e2e-7e8c-42f5-8796-51d522d931a4",
   "metadata": {},
   "source": [
    "## Installing Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9897d90-f5f8-46c4-b151-044c0683b1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in C:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages (1.38.1)\n",
      "Requirement already satisfied: polars-runtime-32==1.38.1 in C:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages (from polars) (1.38.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~yspark (C:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~yspark (C:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~yspark (C:\\Users\\sergi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd343a-66f2-4b78-8cef-9ddac5170bc2",
   "metadata": {},
   "source": [
    "## Eager read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b9c99e4-039c-451d-98d6-9179e2564655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_csv(\"data.csv\")\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c062b0c-a96b-4549-9ee9-b2687b5306ab",
   "metadata": {},
   "source": [
    "## Lazy scan (recommended for bigger CSVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6368b7e-98ad-45a8-a826-7f19dda0efef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n",
      "\n",
      "Csv SCAN [data.csv]\n",
      "PROJECT */33 COLUMNS\n",
      "ESTIMATED ROWS: 580\n",
      "shape: (5, 33)\n",
      "┌──────────┬───────────┬─────────────┬──────────────┬───┬──────────────┬────────────────┬───────────────────────┬──────┐\n",
      "│ id       ┆ diagnosis ┆ radius_mean ┆ texture_mean ┆ … ┆ concave      ┆ symmetry_worst ┆ fractal_dimension_wor ┆      │\n",
      "│ ---      ┆ ---       ┆ ---         ┆ ---          ┆   ┆ points_worst ┆ ---            ┆ st                    ┆ ---  │\n",
      "│ i64      ┆ str       ┆ f64         ┆ f64          ┆   ┆ ---          ┆ f64            ┆ ---                   ┆ str  │\n",
      "│          ┆           ┆             ┆              ┆   ┆ f64          ┆                ┆ f64                   ┆      │\n",
      "╞══════════╪═══════════╪═════════════╪══════════════╪═══╪══════════════╪════════════════╪═══════════════════════╪══════╡\n",
      "│ 842302   ┆ M         ┆ 17.99       ┆ 10.38        ┆ … ┆ 0.2654       ┆ 0.4601         ┆ 0.1189                ┆ null │\n",
      "│ 842517   ┆ M         ┆ 20.57       ┆ 17.77        ┆ … ┆ 0.186        ┆ 0.275          ┆ 0.08902               ┆ null │\n",
      "│ 84300903 ┆ M         ┆ 19.69       ┆ 21.25        ┆ … ┆ 0.243        ┆ 0.3613         ┆ 0.08758               ┆ null │\n",
      "│ 84348301 ┆ M         ┆ 11.42       ┆ 20.38        ┆ … ┆ 0.2575       ┆ 0.6638         ┆ 0.173                 ┆ null │\n",
      "│ 84358402 ┆ M         ┆ 20.29       ┆ 14.34        ┆ … ┆ 0.1625       ┆ 0.2364         ┆ 0.07678               ┆ null │\n",
      "└──────────┴───────────┴─────────────┴──────────────┴───┴──────────────┴────────────────┴───────────────────────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "lf = pl.scan_csv(\"data.csv\")\n",
    "print(lf)                 # shows a LazyFrame (plan, not data)\n",
    "df = lf.collect()         # executes the plan\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8aef4b-99b5-483d-806e-30d29f43dcb2",
   "metadata": {},
   "source": [
    "Polars has two plans for lazy queries:\n",
    "\n",
    "* Naive plan = what you wrote (direct translation of your operations)\n",
    "* Optimized plan = what Polars will actually execute after optimizations\n",
    "\n",
    "optimized=True shows the optimized plan, where Polars may:\n",
    "* remove unused columns (projection pushdown)\n",
    "* push filters earlier (predicate pushdown)\n",
    "* reorder steps for speed\n",
    "  \n",
    "Polars will read the CSV file as the data source and because you used lazy (scan_csv) it will not load it immediately, it will scan it when you do .collect() (or .fetch() / .head().collect() etc).\n",
    "\n",
    "ESTIMATED ROWS: 580. This is Polars’ best guess about how many rows it expects. This is an estimate, not guaranteed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad276916-d275-473e-bc5b-18f05c7cc66d",
   "metadata": {},
   "source": [
    "## Read everything vs select needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbc1c5a3-7c99-4e43-99c3-32fcc5eb1356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csv SCAN [data.csv]\n",
      "PROJECT */33 COLUMNS\n",
      "ESTIMATED ROWS: 580\n"
     ]
    }
   ],
   "source": [
    "lf = pl.scan_csv(\"data.csv\")\n",
    "print(lf.explain(optimized=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e53820-19e8-4275-81f0-a4cd628d1dc6",
   "metadata": {},
   "source": [
    "* Csv SCAN: Polars will read from data.csv\n",
    "* PROJECT /33 COLUMNS: it will read/use all 33 columns (because your lazy pipeline didn’t restrict columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed6c13a0-453d-4796-8d23-19f65cf87995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csv SCAN [data.csv]\n",
      "PROJECT 3/33 COLUMNS\n",
      "ESTIMATED ROWS: 580\n"
     ]
    }
   ],
   "source": [
    "lf = pl.scan_csv(\"data.csv\").select([\"diagnosis\", \"radius_mean\", \"texture_mean\"])\n",
    "print(lf.explain(optimized=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181a441b-a61a-4f8e-9dcf-6c7487000c86",
   "metadata": {},
   "source": [
    "PROJECT 3/33 COLUMNS: Polars will only read 3 columns out of the 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcfb774-e208-4210-a07a-7c9f659efd13",
   "metadata": {},
   "source": [
    "## Pandas vs Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbfaf7b-866b-4dc9-9105-092143354802",
   "metadata": {},
   "source": [
    "Pandas, a widely adopted library, is known for its flexibility and ease of use. However, when dealing with large datasets, Pandas can suffer from performance bottlenecks due to its reliance on single-threaded execution. As the dataset size increases, processing times can become prohibitively long, limiting productivity.\n",
    "\n",
    "Polars has been specifically designed to handle large datasets efficiently. With its lazy evaluation strategy and parallel execution capabilities, Polars excels at processing substantial amounts of data swiftly. By distributing computations across multiple CPU cores, Polars leverages parallelism to deliver impressive performance gains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac891e7-dd1a-40c7-8fc9-11dbd10e1534",
   "metadata": {},
   "source": [
    "## Other Polars operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eef17660-513d-4c06-843d-7aee6df6bb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Carat Weight</th><th>Cut</th><th>Price</th></tr><tr><td>f64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>1.1</td><td>&quot;Ideal&quot;</td><td>5169</td></tr><tr><td>0.83</td><td>&quot;Ideal&quot;</td><td>3470</td></tr><tr><td>0.85</td><td>&quot;Ideal&quot;</td><td>3183</td></tr><tr><td>0.91</td><td>&quot;Ideal&quot;</td><td>4370</td></tr><tr><td>0.83</td><td>&quot;Ideal&quot;</td><td>3171</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌──────────────┬───────┬───────┐\n",
       "│ Carat Weight ┆ Cut   ┆ Price │\n",
       "│ ---          ┆ ---   ┆ ---   │\n",
       "│ f64          ┆ str   ┆ i64   │\n",
       "╞══════════════╪═══════╪═══════╡\n",
       "│ 1.1          ┆ Ideal ┆ 5169  │\n",
       "│ 0.83         ┆ Ideal ┆ 3470  │\n",
       "│ 0.85         ┆ Ideal ┆ 3183  │\n",
       "│ 0.91         ┆ Ideal ┆ 4370  │\n",
       "│ 0.83         ┆ Ideal ┆ 3171  │\n",
       "└──────────────┴───────┴───────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load diamond data from a CSV file\n",
    "df = pl.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diamond.csv')\n",
    "\n",
    "\n",
    "# Select specific columns: carat, cut, and price\n",
    "selected_df = df.select(['Carat Weight', 'Cut', 'Price'])\n",
    "\n",
    "\n",
    "# show selected_df head\n",
    "selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "954b315a-18ea-4e25-8130-0b7c0793ab8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Carat Weight</th><th>Cut</th><th>Color</th><th>Clarity</th><th>Polish</th><th>Symmetry</th><th>Report</th><th>Price</th></tr><tr><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>2.11</td><td>&quot;Ideal&quot;</td><td>&quot;H&quot;</td><td>&quot;SI1&quot;</td><td>&quot;VG&quot;</td><td>&quot;VG&quot;</td><td>&quot;GIA&quot;</td><td>18609</td></tr><tr><td>2.51</td><td>&quot;Very Good&quot;</td><td>&quot;G&quot;</td><td>&quot;VS2&quot;</td><td>&quot;VG&quot;</td><td>&quot;VG&quot;</td><td>&quot;GIA&quot;</td><td>34361</td></tr><tr><td>2.2</td><td>&quot;Ideal&quot;</td><td>&quot;H&quot;</td><td>&quot;VS2&quot;</td><td>&quot;EX&quot;</td><td>&quot;VG&quot;</td><td>&quot;GIA&quot;</td><td>22241</td></tr><tr><td>2.6</td><td>&quot;Ideal&quot;</td><td>&quot;G&quot;</td><td>&quot;VS2&quot;</td><td>&quot;EX&quot;</td><td>&quot;EX&quot;</td><td>&quot;GIA&quot;</td><td>37621</td></tr><tr><td>2.02</td><td>&quot;Good&quot;</td><td>&quot;I&quot;</td><td>&quot;VVS2&quot;</td><td>&quot;EX&quot;</td><td>&quot;VG&quot;</td><td>&quot;GIA&quot;</td><td>19756</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌──────────────┬───────────┬───────┬─────────┬────────┬──────────┬────────┬───────┐\n",
       "│ Carat Weight ┆ Cut       ┆ Color ┆ Clarity ┆ Polish ┆ Symmetry ┆ Report ┆ Price │\n",
       "│ ---          ┆ ---       ┆ ---   ┆ ---     ┆ ---    ┆ ---      ┆ ---    ┆ ---   │\n",
       "│ f64          ┆ str       ┆ str   ┆ str     ┆ str    ┆ str      ┆ str    ┆ i64   │\n",
       "╞══════════════╪═══════════╪═══════╪═════════╪════════╪══════════╪════════╪═══════╡\n",
       "│ 2.11         ┆ Ideal     ┆ H     ┆ SI1     ┆ VG     ┆ VG       ┆ GIA    ┆ 18609 │\n",
       "│ 2.51         ┆ Very Good ┆ G     ┆ VS2     ┆ VG     ┆ VG       ┆ GIA    ┆ 34361 │\n",
       "│ 2.2          ┆ Ideal     ┆ H     ┆ VS2     ┆ EX     ┆ VG       ┆ GIA    ┆ 22241 │\n",
       "│ 2.6          ┆ Ideal     ┆ G     ┆ VS2     ┆ EX     ┆ EX       ┆ GIA    ┆ 37621 │\n",
       "│ 2.02         ┆ Good      ┆ I     ┆ VVS2    ┆ EX     ┆ VG       ┆ GIA    ┆ 19756 │\n",
       "└──────────────┴───────────┴───────┴─────────┴────────┴──────────┴────────┴───────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load diamond data from a CSV file\n",
    "df = pl.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diamond.csv')\n",
    "\n",
    "\n",
    "# filter the df with condition\n",
    "filtered_df = df.filter(pl.col('Carat Weight') > 2.0)\n",
    "\n",
    "\n",
    "# show filtered_df head\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d95844-2cb9-44b1-898e-6d285d2f7939",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe5b0943-41b2-449e-b449-3addecad9f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Carat Weight</th><th>Cut</th><th>Color</th><th>Clarity</th><th>Polish</th><th>Symmetry</th><th>Report</th><th>Price</th></tr><tr><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>1.1</td><td>&quot;Ideal&quot;</td><td>&quot;H&quot;</td><td>&quot;SI1&quot;</td><td>&quot;VG&quot;</td><td>&quot;EX&quot;</td><td>&quot;GIA&quot;</td><td>5169</td></tr><tr><td>0.83</td><td>&quot;Ideal&quot;</td><td>&quot;H&quot;</td><td>&quot;VS1&quot;</td><td>&quot;ID&quot;</td><td>&quot;ID&quot;</td><td>&quot;AGSL&quot;</td><td>3470</td></tr><tr><td>0.85</td><td>&quot;Ideal&quot;</td><td>&quot;H&quot;</td><td>&quot;SI1&quot;</td><td>&quot;EX&quot;</td><td>&quot;EX&quot;</td><td>&quot;GIA&quot;</td><td>3183</td></tr><tr><td>0.91</td><td>&quot;Ideal&quot;</td><td>&quot;E&quot;</td><td>&quot;SI1&quot;</td><td>&quot;VG&quot;</td><td>&quot;VG&quot;</td><td>&quot;GIA&quot;</td><td>4370</td></tr><tr><td>0.83</td><td>&quot;Ideal&quot;</td><td>&quot;G&quot;</td><td>&quot;SI1&quot;</td><td>&quot;EX&quot;</td><td>&quot;EX&quot;</td><td>&quot;GIA&quot;</td><td>3171</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌──────────────┬───────┬───────┬─────────┬────────┬──────────┬────────┬───────┐\n",
       "│ Carat Weight ┆ Cut   ┆ Color ┆ Clarity ┆ Polish ┆ Symmetry ┆ Report ┆ Price │\n",
       "│ ---          ┆ ---   ┆ ---   ┆ ---     ┆ ---    ┆ ---      ┆ ---    ┆ ---   │\n",
       "│ f64          ┆ str   ┆ str   ┆ str     ┆ str    ┆ str      ┆ str    ┆ i64   │\n",
       "╞══════════════╪═══════╪═══════╪═════════╪════════╪══════════╪════════╪═══════╡\n",
       "│ 1.1          ┆ Ideal ┆ H     ┆ SI1     ┆ VG     ┆ EX       ┆ GIA    ┆ 5169  │\n",
       "│ 0.83         ┆ Ideal ┆ H     ┆ VS1     ┆ ID     ┆ ID       ┆ AGSL   ┆ 3470  │\n",
       "│ 0.85         ┆ Ideal ┆ H     ┆ SI1     ┆ EX     ┆ EX       ┆ GIA    ┆ 3183  │\n",
       "│ 0.91         ┆ Ideal ┆ E     ┆ SI1     ┆ VG     ┆ VG       ┆ GIA    ┆ 4370  │\n",
       "│ 0.83         ┆ Ideal ┆ G     ┆ SI1     ┆ EX     ┆ EX       ┆ GIA    ┆ 3171  │\n",
       "└──────────────┴───────┴───────┴─────────┴────────┴──────────┴────────┴───────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load diamond data from a CSV file\n",
    "df = pl.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diamond.csv')\n",
    "\n",
    "# drop missing values\n",
    "cleaned_df = df.drop_nulls()\n",
    "\n",
    "# show cleaned_df head\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f88f14-fca2-4fea-afc0-530c450ddc7d",
   "metadata": {},
   "source": [
    "## Advantages of Polars for large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a60862-1d30-4fd9-8681-a3415b15af1e",
   "metadata": {},
   "source": [
    "Polars offers several key advantages over pandas, particularly when dealing with large datasets:\n",
    "\n",
    "* **Performance**: Polars is significantly faster than pandas in many operations, thanks to its Rust backend and parallel processing capabilities. This speedup can be crucial when working with large datasets where performance is a bottleneck.\n",
    "* **Memory Efficiency**: Polars utilizes Rust's memory model, which can lead to more efficient memory usage compared to pandas, especially when handling data that doesn't fit comfortably in RAM.\n",
    "* **Lazy Evaluation**: Polars' lazy evaluation approach defers computations until necessary, reducing unnecessary work and potentially leading to significant performance improvements.\n",
    "* **Immutability** : Polars DataFrames are immutable, preventing accidental in-place modifications and promoting functional-style programming, which can lead to more predictable and maintainable code.\n",
    "* **Expressive API**: Polars provides an expressive API for data manipulation tasks, making it easy to perform complex operations with concise and readable code.\n",
    "* **Query Optimization**: Polars automatically optimizes query execution plans, aiming for efficient use of resources and further enhancing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505fc59c-2fd8-4044-b754-84844592c577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d0389b3-5302-4965-a1ac-f3737124496c",
   "metadata": {},
   "source": [
    "# From CSV to Classifier: Fast Data Preparation with Polars and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39b2227a-934b-49b9-a8ce-59e13fde8bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (569, 33)\n",
      "Columns: ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean'] ...\n",
      "X shape: (569, 30) y shape: (569,)\n",
      "\n",
      "Accuracy: 0.9649122807017544\n",
      "\n",
      "Confusion matrix:\n",
      " [[71  1]\n",
      " [ 3 39]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Benign(0)       0.96      0.99      0.97        72\n",
      "Malignant(1)       0.97      0.93      0.95        42\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "\n",
      "Number of features: 30\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "df = pl.read_csv(\"https://raw.githubusercontent.com/kishan0725/Breast-Cancer-Wisconsin-Diagnostic/master/data.csv\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns[:8], \"...\")\n",
    "\n",
    "#cleaning\n",
    "all_null_cols = [c for c in df.columns if df.select(pl.col(c).is_null().all()).item()]\n",
    "if all_null_cols:\n",
    "    df = df.drop(all_null_cols)\n",
    "\n",
    "# Drop ID column if present\n",
    "if \"id\" in df.columns:\n",
    "    df = df.drop(\"id\")\n",
    "\n",
    "# Target encoding: diagnosis (M=malignant, B=benign) -> 1/0\n",
    "if \"diagnosis\" not in df.columns:\n",
    "    raise ValueError(\"Expected a 'diagnosis' column in the CSV.\")\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.col(\"diagnosis\") == \"M\").then(1).otherwise(0).alias(\"label\")\n",
    ").drop(\"diagnosis\")\n",
    "\n",
    "# build X, y (convert to numpy for scikit-learn)\n",
    "X = df.drop(\"label\").to_numpy()\n",
    "y = df[\"label\"].to_numpy()\n",
    "\n",
    "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "#  Model pipeline: scaling + logistic regression\n",
    "model = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"\\nAccuracy:\", acc)\n",
    "print(\"\\nConfusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, target_names=[\"Benign(0)\", \"Malignant(1)\"]))\n",
    "\n",
    "# Optional: show feature count + sanity checks\n",
    "print(\"\\nNumber of features:\", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505fa6b-0348-4a2c-9779-5beead8f0c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
